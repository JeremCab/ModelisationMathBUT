{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a361880",
   "metadata": {},
   "source": [
    "# Reconnaissance faciale via $k$ plus proches voisins ($k$-NN)\n",
    "\n",
    ">## Partie 1: Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f35df",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691df55",
   "metadata": {},
   "source": [
    "- La librairie `cv2` permet la détection automatique de visages, entre autres.\n",
    "\n",
    "- La librairie `pickle` permet de sauvegarder vos modèles une fois entraînés, et de les recharger pour pouvoir les utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca4ffdf-be84-4a62-84f4-29770c83d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a41298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089bbe3",
   "metadata": {},
   "source": [
    "## Création du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0183880",
   "metadata": {},
   "source": [
    "Le code suivant permet de créer un **dataset** d'images que vous utiliserez dans votre projet de **reconnaissance faciale**. Ce dataset contiendra des images de vous-même associées à votre nom ainsi que des images d'autres personnes (par exemple vos camarades) associées à leurs noms. **À chaque fois que vos relancez le code ci-dessous, votre caméra capture 10 images de la personne qui se trouve devant vootre PC et ajoute ces dernières à votre dataset.** \n",
    "\n",
    "Le code effectue les opérations suivantes. Premièrement, on lit le flux vidéo de votre caméra et on détecte automatiquement les visages dans chaque image de ce flux en utilisant le **classificateur en cascade de Haar (Haar cascade classifier)** de la librairie `OpenCV`. \n",
    "\n",
    "Plus précisément, tant que la variable `ret` est vraie, indiquant que le flux vidéo est lu correctement, pour chaque image capturée par la caméras, on effectue les opérations suivantes:\n",
    "1. on convertit l'image en niveaux de gris;\n",
    "2. on détecte les coordonnées du visage en utilisant le classificateur en cascade de Haar;\n",
    "3. on recadre la région du visage et la redimensionne en $50 \\times 50$ pixels;\n",
    "4. on ajoute l'image du visage redimensionné à la liste `donnees_visage`, à chaque intervalle de $10$ images.\n",
    "\n",
    "Une fois que $10$ images de votre visage ont été collecteés, ou si l'utilisateur appuye sur la touche `Esc`, on met fin à la boucle et enregistre les images dans la liste `donnees_visage` sous forme d'un tableau `NumPy`.\n",
    "\n",
    "Par la suite, l'existence des fichiers `noms.pkl` et `visages.pkl` est vérifiée. S'ils n'existent pas, de nouveaux fichiers sont créés, la variable `nom` est enregistrée dans `noms.pkl` et les données de visage sont enregistrées dans `visages.pkl`. Si ces fichiers existent déjà, le code charge les données existantes, ajoute les nouvelles données de visage et noms, et les réenregistre le tout dans ces fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ba3a98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrez votre nom:  Jeremie\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 4 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdata/visages.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[32m     90\u001b[39m     visages = pickle.load(w)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m visages = np.append(visages, donnees_visage, axis=\u001b[32m0\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdata/visages.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[32m     94\u001b[39m     pickle.dump(visages, w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:5711\u001b[39m, in \u001b[36mappend\u001b[39m\u001b[34m(arr, values, axis)\u001b[39m\n\u001b[32m   5709\u001b[39m     values = ravel(values)\n\u001b[32m   5710\u001b[39m     axis = arr.ndim-\u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5711\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate((arr, values), axis=axis)\n",
      "\u001b[31mValueError\u001b[39m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 4 dimension(s)"
     ]
    }
   ],
   "source": [
    "# ================== #\n",
    "# Variables globales #\n",
    "# ================== #\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")         # création d'un répertoire data\n",
    "\n",
    "nb_images_collectees = 15    # nombre d'image que vous voulez collecter\n",
    "\n",
    "donnees_visage = []\n",
    "\n",
    "camera = cv2.VideoCapture(0) # 0 pour 'built-in' caméra, 1 pour caméra externe\n",
    "\n",
    "cascade_visage = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# =============================== #\n",
    "# Capture des data: nom et images #\n",
    "# =============================== #\n",
    "nom = input(\"Entrez votre nom: \")\n",
    "\n",
    "ret = True\n",
    "i = 0\n",
    "\n",
    "while(ret):\n",
    "    \n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        \n",
    "        gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        coordonnees_visage = cascade_visage.detectMultiScale(gris, 1.3, 4)\n",
    "\n",
    "        for (a, b, w, h) in coordonnees_visage:\n",
    "            \n",
    "            visages = frame[b:b+h, a:a+w, :]\n",
    "            visages_redimensionnes = cv2.resize(visages, (50, 50))\n",
    "            \n",
    "            if i % 10 == 0 and len(donnees_visage) < nb_images_collectees:\n",
    "                \n",
    "                donnees_visage.append(visages_redimensionnes)\n",
    "                \n",
    "            cv2.rectangle(frame, (a, b), (a+w, b+h), (255, 0, 0), 2)\n",
    "            \n",
    "        i += 1\n",
    "\n",
    "        cv2.imshow('Visages', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27 or len(donnees_visage) >= nb_images_collectees:\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        \n",
    "        print('erreur')\n",
    "        break\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "\n",
    "donnees_visage = np.asarray(donnees_visage)\n",
    "# donnees_visage = donnees_visage.reshape(10, -1)\n",
    "\n",
    "\n",
    "# ====================================== #\n",
    "# Enregistrement des data: nom et images #\n",
    "# ====================================== #\n",
    "if 'noms.pkl' not in os.listdir('data/'):\n",
    "    \n",
    "    noms = [nom]*10\n",
    "    with open('data/noms.pkl', 'wb') as file:\n",
    "        pickle.dump(noms, file)\n",
    "else:\n",
    "    \n",
    "    with open('data/noms.pkl', 'rb') as file:\n",
    "        noms = pickle.load(file)\n",
    "\n",
    "    noms = noms + [nom]*10\n",
    "    with open('data/noms.pkl', 'wb') as file:\n",
    "        pickle.dump(noms, file)\n",
    "\n",
    "\n",
    "if 'visages.pkl' not in os.listdir('data/'):\n",
    "    \n",
    "    with open('data/visages.pkl', 'wb') as w:\n",
    "        pickle.dump(donnees_visage, w)\n",
    "else:\n",
    "    \n",
    "    with open('data/visages.pkl', 'rb') as w:\n",
    "        visages = pickle.load(w)\n",
    "\n",
    "    visages = np.append(visages, donnees_visage, axis=0)\n",
    "    with open('data/visages.pkl', 'wb') as w:\n",
    "        pickle.dump(visages, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bec3e0",
   "metadata": {},
   "source": [
    "## Visualisation du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df3d2c",
   "metadata": {},
   "source": [
    "Le instructions suivantes permettent de loader votre dataset et de comprendre comment sont stockées les data.\n",
    "\n",
    "Prêtez attention aux types de vos data, en particulier à la dimension de vos images, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4c5cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/noms.pkl\", \"rb\") as fh:\n",
    "    noms = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3af5a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie',\n",
       " 'Jeremie']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7fc242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/visages.pkl\", \"rb\") as fh:\n",
    "    visages = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10dab6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8436555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ef19a8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sample_1 = visages[\u001b[32m0\u001b[39m]\n\u001b[32m      2\u001b[39m sample_1.shape\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "sample_1 = visages[0]\n",
    "sample_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3539263",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plt.imshow(sample_1, interpolation=\u001b[33m\"\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_1' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(sample_1, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac4aaef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_2 = visages[5]\n",
    "sample_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed489bfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plt.imshow(sample_2, interpolation=\u001b[33m\"\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_2' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(sample_2, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a26147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
